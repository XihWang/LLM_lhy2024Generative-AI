{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e3a879-d9f9-4252-8298-4340b59169ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List,Dict,Tuple\n",
    "\n",
    "import openai\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4d71f8-4c4d-4c84-8964-aa75ad3600b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api sets up\n"
     ]
    }
   ],
   "source": [
    "OPENAI_API_KEY = 'sk-996c9b87a8f74b42825211b62635769c'\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key= OPENAI_API_KEY,\n",
    "    base_url=\"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model = 'qwen-turbo',\n",
    "        messages = [{'role':'user','content':'test'}],\n",
    "        max_tokens = 1\n",
    "    )\n",
    "    print('api sets up')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'API有问题 请检查{e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b3b093-1bf5-4695-947f-e473171c07e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-a849ec94-bd97-9adf-84d4-03773fba515f', choices=[Choice(finish_reason='stop reschedule', index=0, logprobs=None, message=ChatCompletionMessage(content='It', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1736242634, model='qwen-turbo', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=1, prompt_tokens=9, total_tokens=10, completion_tokens_details=None, prompt_tokens_details=None))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133ed7e7-d20f-4a4a-9ca3-b6d48ee51151",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason='stop reschedule', index=0, logprobs=None, message=ChatCompletionMessage(content='It', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e07feeb0-8feb-4071-9d4e-4cc5b534bfe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop reschedule', index=0, logprobs=None, message=ChatCompletionMessage(content='It', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f982cb-b310-403e-b002-b43a471e868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='It', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e470aa-0f7e-4e02-8d9e-3122840cad84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968d7f2a-4166-4d13-ba3c-26509c4517a7",
   "metadata": {},
   "source": [
    "## 文本概括"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "088ec84d-636c-4eea-a54c-158d64cdb680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\gradio\\queueing.py\", line 536, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\gradio\\blocks.py\", line 1935, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\gradio\\blocks.py\", line 1520, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2357, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 864, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\gradio\\utils.py\", line 826, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "  File \"C:\\Users\\Lollipop\\AppData\\Local\\Temp\\ipykernel_2528\\1476575872.py\", line 33, in export_summarization\n",
      "    with open(\"files/part1.json\", \"w\") as file:\n",
      "  File \"D:\\Pycharm\\venv\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 310, in _modified_open\n",
      "    return io_open(file, *args, **kwargs)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'files/part1.json'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_for_summarization = \"请将以下文章概括成几句话。\"\n",
    "\n",
    "# 重置对话的函数\n",
    "def reset() -> List:\n",
    "    return []\n",
    "\n",
    "# 调用模型生成摘要的函数\n",
    "def interact_summarization(prompt: str, article: str, temp=1.0) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "    * 参数:\n",
    "      - prompt: 我们在此部分中使用的提示词\n",
    "      - article: 需要摘要的文章\n",
    "      - temp: 模型的温度参数。温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\n",
    "    '''\n",
    "    input = f\"{prompt}\\n{article}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",  # 使用阿里云 DashScope 的模型\n",
    "        messages=[{'role': 'user', 'content': input}],\n",
    "        temperature=temp,\n",
    "        max_tokens=200,  # 你需要注意到这里设置了文本的长度上限。\n",
    "    )\n",
    "\n",
    "    return [(input, response.choices[0].message.content)]\n",
    "\n",
    "# 导出整个对话内容的函数\n",
    "def export_summarization(chatbot: List[Tuple[str, str]], article: str) -> None:\n",
    "    '''\n",
    "    * 参数:\n",
    "      - chatbot: 模型的对话记录，存储在元组列表中\n",
    "      - article: 需要摘要的文章\n",
    "    '''\n",
    "    target = {\"chatbot\": chatbot, \"article\": article}\n",
    "    with open(\"files/part1.json\", \"w\") as file:\n",
    "        json.dump(target, file)\n",
    "\n",
    "# 生成 Gradio 的UI界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 第1部分：摘要\\n填写任何你喜欢的文章，让聊天机器人为你总结！\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    # 这里的value指的是默认值\n",
    "    prompt_textbox = gr.Textbox(label=\"提示词\", value=prompt_for_summarization, visible=True)\n",
    "    article_textbox = gr.Textbox(label=\"文章\", interactive=True, value=\"我家的后面有一个很大的园，相传叫作百草园。现在是早已并屋子一起卖给朱 文公的子孙了，连那最末次的相见也已经隔了七八年，其中似乎确凿只有一些野草 ；但那时却是我的乐园。 　　不必说碧绿的菜畦，光滑的石井栏，高大的皂荚树，紫红的桑椹；也不必说鸣 蝉在树叶里长吟，肥胖的黄蜂伏在菜花上，轻捷的叫天子（云雀）忽然从草间直窜 向云霄里去了。单是周围的短短的泥墙根一带，就有无限趣味。油蛉在这里低唱， 蟋蟀们在这里弹琴。翻开断砖来，有时会遇见蜈蚣；还有斑蝥，倘若用手指按住它 的脊梁，便会拍的一声，从后窍喷出一阵烟雾。何首乌藤和木莲藤缠络着，木莲有 莲房一般的果实，何首乌有拥肿的根。有人说，何首乌根是有象人形的，吃了便可 以成仙，我于是常常拔它起来，牵连不断地拔起来，也曾因此弄坏了泥墙，却从来 没有见过有一块根象人样。如果不怕刺，还可以摘到覆盆子，象小珊瑚珠攒成的小 球，又酸又甜，色味都比桑椹要好得远。 　 　　长的草里是不去的，因为相传这园里有一条很大的赤练蛇。 　　长妈妈曾经讲给我一个故事听：先前，有一个读书人住在古庙里用功，晚间， 在院子里纳凉的时候，突然听到有人在叫他。答应着，四面看时，却见一个美女的 脸露在墙头上，向他一笑，隐去了。他很高兴；但竟给那走来夜谈的老和尚识破了 机关。说他脸上有些妖气，一定遇见“美女蛇”了；这是人首蛇身的怪物，能唤人 名，倘一答应，夜间便要来吃这人的肉的。他自然吓得要死，而那老和尚却道无妨 ，给他一个小盒子，说只要放在枕边，便可高枕而卧。他虽然照样办，却总是睡不 着，——当然睡不着的。到半夜，果然来了，沙沙沙！门外象是风雨声。他正抖作 一团时，却听得豁的一声，一道金光从枕边飞出，外面便什么声音也没有了，那金 光也就飞回来，敛在盒子里。后来呢？后来，老和尚说，这是飞蜈蚣，它能吸蛇的 脑髓，美女蛇就被它治死了。 　　结末的教训是：所以倘有陌生的声音叫你的名字，你万不可答应他。　　 　　这故事很使我觉得做人之险，夏夜乘凉，往往有些担心，不敢去看墙上，而且 极想得到一盒老和尚那样的飞蜈蚣。走到百草园的草丛旁边时，也常常这样想。但 直到现在，总还没有得到，但也没有遇见过赤练蛇和美女蛇。叫我名字的陌生声音 自然是常有的，然而都不是美女蛇。 　　冬天的百草园比较的无味；雪一下，可就两样了。拍雪人（将自己的全形印在 雪上）和塑雪罗汉需要人们鉴赏，这是荒园，人迹罕至，所以不相宜，只好来捕鸟 。薄薄的雪，是不行的；总须积雪盖了地面一两天，鸟雀们久已无处觅食的时候才 好。扫开一块雪，露出地面，用一支短棒支起一面大的竹筛来，下面撒些秕谷，棒 上系一条长绳，人远远地牵着，看鸟雀下来啄食，走到竹筛底下的时候，将绳子一 拉，便罩住了。但所得的是麻雀居多，也有白颊的“张飞鸟”，性子很躁，养不过 夜的。 　　这是闰土的父亲所传授的方法，我却不大能用。明明见它们进去了，拉了绳， 跑去一看，却什么都没有，费了半天力，捉住的不过三四只。闰土的父亲是小半天 便能捕获几十只，装在叉袋里叫着撞着的。我曾经问他得失的缘由，他只静静地笑 道：你太性急，来不及等它走到中间去。 　　我不知道为什么家里的人要将我送进书塾里去了，而且还是全城中称为最严厉 的书塾。也许是因为拔何首乌毁了泥墙罢，也许是因为将砖头抛到间壁的梁家去了 罢，也许是因为站在石井栏上跳下来罢，……都无从知道。总而言之：我将不能常 到百草园了。Ａｄｅ，我的蟋蟀们！Ａｄｅ，我的覆盆子们和木莲们！ 　　出门向东，不上半里，走过一道石桥，便是我的先生的家了。从一扇黑油的竹 门进去，第三间是书房。中间挂着一块扁道：三味书屋；扁下面是一幅画，画着一 只很肥大的梅花鹿伏在古树下。没有孔子牌位，我们便对着那扁和鹿行礼。第一次 算是拜孔子，第二次算是拜先生。 　　第二次行礼时，先生便和蔼地在一旁答礼。他是一个高而瘦的老人，须发都花 白了，还戴着大眼镜。我对他很恭敬，因为我早听到，他是本城中极方正，质朴， 博学的人。 　　不知从那里听来的，东方朔也很渊博，他认识一种虫，名曰“怪哉”，冤气所 化，用酒一浇，就消释了。我很想详细地知道这故事，但阿长是不知道的，因为她 毕竟不渊博。现在得到机会了，可以问先生。 　　“先生，‘怪哉’这虫，是怎么一回事？……”我上了生书，将要退下来的时 候，赶忙问。 　　“不知道！”他似乎很不高兴，脸上还有怒色了。 　　我才知道做学生是不应该问这些事的，只要读书，因为他是渊博的宿儒，决不 至于不知道，所谓不知道者，乃是不愿意说。年纪比我大的人，往往如此，我遇见 过好几回了。 　　我就只读书，正午习字，晚上对课。先生最初这几天对我很严厉，后来却好起 来了，不过给我读的书渐渐加多，对课也渐渐地加上字去，从三言到五言，终于到 七言。 　　三味书屋后面也有一个园，虽然小，但在那里也可以爬上花坛去折腊梅花，在 地上或桂花树上寻蝉蜕。最好的工作是捉了苍蝇喂蚂蚁，静悄悄地没有声音。然而 同窗们到园里的太多，太久，可就不行了，先生在书房里便大叫起来：—— 　　“人都到那里去了？” 　　人们便一个一个陆续走回去；一同回去，也不行的。他有一条戒尺，但是不常 用，也有罚跪的规矩，但也不常用，普通总不过瞪几眼，大声道：—— 　　“读书！” 　　于是大家放开喉咙读一阵书，真是人声鼎沸。有念“仁远乎哉我欲仁斯仁至矣 ”的，有念“笑人齿缺曰狗窦大开”的，有念“上九潜龙勿用”的，有念“厥土下 上上错厥贡苞茅橘柚”的……先生自己也念书。后来，我们的声音便低下去，静下 去了，只有他还大声朗读着：—— 　　“铁如意，指挥倜傥，一座皆惊呢～～；金叵罗，颠倒淋漓噫，千杯未醉嗬～ ～……” 　　我疑心这是极好的文章，因为读到这里，他总是微笑起来，而且将头仰起，摇 着，向后面拗过去，拗过去。 　　先生读书入神的时候，于我们是很相宜的。有几个便用纸糊的盔甲套在指甲上 做戏。我是画画儿，用一种叫作“荆川纸”的，蒙在小说的绣像上一个个描下来， 象习字时候的影写一样。读的书多起来，画的画也多起来；书没有读成，画的成绩 却不少了，最成片断的是《荡寇志》和《西游记》的绣像，都有一大本。后来，因 为要钱用，卖给一个有钱的同窗了。他的父亲是开锡箔店的；听说现在自己已经做 了店主，而且快要升到绅士的地位了。这东西早已没有了罢。 　　　　　　　　　　　　　　　　　　 　　九月十八日。\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 温度调节\\n温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\")\n",
    "        temperature_slider = gr.Slider(0.0, 2.0, 1.0, step=0.1, label=\"温度\")\n",
    "\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"发送\")\n",
    "        reset_button = gr.Button(value=\"重置\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 保存结果\\n当你对结果满意后，点击导出按钮保存结果。\")\n",
    "        export_button = gr.Button(value=\"导出\")\n",
    "\n",
    "    # 连接按钮与函数\n",
    "    sent_button.click(interact_summarization, inputs=[prompt_textbox, article_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_summarization, inputs=[chatbot, article_textbox])\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4c9e8b8-7939-4916-9415-1f9f2ade0c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('files/part1.json', 'r') as f:\n",
    "    context = json.load(f)\n",
    "\n",
    "chatbot = context['chatbot']\n",
    "article = context['article']\n",
    "summarization = chatbot[0][-1]\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown('# 第1部分：摘要\\n你可以查看文章和摘要！')\n",
    "    chatbot = gr.Chatbot(value=chatbot)\n",
    "    article_textbox = gr.Textbox(label='文章', interactive=False, value=article)\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown('# 检查')\n",
    "        gr.Textbox(label='文章', value = article, show_copy_button=True)\n",
    "        gr.Textbox(label='摘要', value = summarization,show_copy_button=True)\n",
    "\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6698d2c4-e44f-4a82-9b53-d1698e9f8bac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_for_summarization = \"You are a Nobel Prize in Literature, you are an expert at summing up articles, you have a thoughtful mind, you can think step by step to summarize the following articles into a few sentences, please summarize the following content。\"\n",
    "\n",
    "# 重置对话的函数\n",
    "def reset() -> List:\n",
    "    return []\n",
    "\n",
    "# 调用模型生成摘要的函数\n",
    "def interact_summarization(prompt: str, article: str, temp=1.0) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "    * 参数:\n",
    "      - prompt: 我们在此部分中使用的提示词\n",
    "      - article: 需要摘要的文章\n",
    "      - temp: 模型的温度参数。温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\n",
    "    '''\n",
    "    input = f\"{prompt}\\n{article}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",  # 使用阿里云 DashScope 的模型\n",
    "        messages=[{'role': 'user', 'content': input}],\n",
    "        temperature=temp,\n",
    "        max_tokens=200,  # 你需要注意到这里设置了文本的长度上限。\n",
    "    )\n",
    "\n",
    "    return [(input, response.choices[0].message.content)]\n",
    "\n",
    "# 导出整个对话内容的函数\n",
    "def export_summarization(chatbot: List[Tuple[str, str]], article: str) -> None:\n",
    "    '''\n",
    "    * 参数:\n",
    "      - chatbot: 模型的对话记录，存储在元组列表中\n",
    "      - article: 需要摘要的文章\n",
    "    '''\n",
    "    target = {\"chatbot\": chatbot, \"article\": article}\n",
    "    with open(\"files/part1.json\", \"w\") as file:\n",
    "        json.dump(target, file)\n",
    "\n",
    "# 生成 Gradio 的UI界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 第1部分：摘要\\n填写任何你喜欢的文章，让聊天机器人为你总结！\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    # 这里的value指的是默认值\n",
    "    prompt_textbox = gr.Textbox(label=\"提示词\", value=prompt_for_summarization, visible=True)\n",
    "    article_textbox = gr.Textbox(label=\"文章\", interactive=True, value=\"我家的后面有一个很大的园，相传叫作百草园。现在是早已并屋子一起卖给朱 文公的子孙了，连那最末次的相见也已经隔了七八年，其中似乎确凿只有一些野草 ；但那时却是我的乐园。 　　不必说碧绿的菜畦，光滑的石井栏，高大的皂荚树，紫红的桑椹；也不必说鸣 蝉在树叶里长吟，肥胖的黄蜂伏在菜花上，轻捷的叫天子（云雀）忽然从草间直窜 向云霄里去了。单是周围的短短的泥墙根一带，就有无限趣味。油蛉在这里低唱， 蟋蟀们在这里弹琴。翻开断砖来，有时会遇见蜈蚣；还有斑蝥，倘若用手指按住它 的脊梁，便会拍的一声，从后窍喷出一阵烟雾。何首乌藤和木莲藤缠络着，木莲有 莲房一般的果实，何首乌有拥肿的根。有人说，何首乌根是有象人形的，吃了便可 以成仙，我于是常常拔它起来，牵连不断地拔起来，也曾因此弄坏了泥墙，却从来 没有见过有一块根象人样。如果不怕刺，还可以摘到覆盆子，象小珊瑚珠攒成的小 球，又酸又甜，色味都比桑椹要好得远。 　 　　长的草里是不去的，因为相传这园里有一条很大的赤练蛇。 　　长妈妈曾经讲给我一个故事听：先前，有一个读书人住在古庙里用功，晚间， 在院子里纳凉的时候，突然听到有人在叫他。答应着，四面看时，却见一个美女的 脸露在墙头上，向他一笑，隐去了。他很高兴；但竟给那走来夜谈的老和尚识破了 机关。说他脸上有些妖气，一定遇见“美女蛇”了；这是人首蛇身的怪物，能唤人 名，倘一答应，夜间便要来吃这人的肉的。他自然吓得要死，而那老和尚却道无妨 ，给他一个小盒子，说只要放在枕边，便可高枕而卧。他虽然照样办，却总是睡不 着，——当然睡不着的。到半夜，果然来了，沙沙沙！门外象是风雨声。他正抖作 一团时，却听得豁的一声，一道金光从枕边飞出，外面便什么声音也没有了，那金 光也就飞回来，敛在盒子里。后来呢？后来，老和尚说，这是飞蜈蚣，它能吸蛇的 脑髓，美女蛇就被它治死了。 　　结末的教训是：所以倘有陌生的声音叫你的名字，你万不可答应他。　　 　　这故事很使我觉得做人之险，夏夜乘凉，往往有些担心，不敢去看墙上，而且 极想得到一盒老和尚那样的飞蜈蚣。走到百草园的草丛旁边时，也常常这样想。但 直到现在，总还没有得到，但也没有遇见过赤练蛇和美女蛇。叫我名字的陌生声音 自然是常有的，然而都不是美女蛇。 　　冬天的百草园比较的无味；雪一下，可就两样了。拍雪人（将自己的全形印在 雪上）和塑雪罗汉需要人们鉴赏，这是荒园，人迹罕至，所以不相宜，只好来捕鸟 。薄薄的雪，是不行的；总须积雪盖了地面一两天，鸟雀们久已无处觅食的时候才 好。扫开一块雪，露出地面，用一支短棒支起一面大的竹筛来，下面撒些秕谷，棒 上系一条长绳，人远远地牵着，看鸟雀下来啄食，走到竹筛底下的时候，将绳子一 拉，便罩住了。但所得的是麻雀居多，也有白颊的“张飞鸟”，性子很躁，养不过 夜的。 　　这是闰土的父亲所传授的方法，我却不大能用。明明见它们进去了，拉了绳， 跑去一看，却什么都没有，费了半天力，捉住的不过三四只。闰土的父亲是小半天 便能捕获几十只，装在叉袋里叫着撞着的。我曾经问他得失的缘由，他只静静地笑 道：你太性急，来不及等它走到中间去。 　　我不知道为什么家里的人要将我送进书塾里去了，而且还是全城中称为最严厉 的书塾。也许是因为拔何首乌毁了泥墙罢，也许是因为将砖头抛到间壁的梁家去了 罢，也许是因为站在石井栏上跳下来罢，……都无从知道。总而言之：我将不能常 到百草园了。Ａｄｅ，我的蟋蟀们！Ａｄｅ，我的覆盆子们和木莲们！ 　　出门向东，不上半里，走过一道石桥，便是我的先生的家了。从一扇黑油的竹 门进去，第三间是书房。中间挂着一块扁道：三味书屋；扁下面是一幅画，画着一 只很肥大的梅花鹿伏在古树下。没有孔子牌位，我们便对着那扁和鹿行礼。第一次 算是拜孔子，第二次算是拜先生。 　　第二次行礼时，先生便和蔼地在一旁答礼。他是一个高而瘦的老人，须发都花 白了，还戴着大眼镜。我对他很恭敬，因为我早听到，他是本城中极方正，质朴， 博学的人。 　　不知从那里听来的，东方朔也很渊博，他认识一种虫，名曰“怪哉”，冤气所 化，用酒一浇，就消释了。我很想详细地知道这故事，但阿长是不知道的，因为她 毕竟不渊博。现在得到机会了，可以问先生。 　　“先生，‘怪哉’这虫，是怎么一回事？……”我上了生书，将要退下来的时 候，赶忙问。 　　“不知道！”他似乎很不高兴，脸上还有怒色了。 　　我才知道做学生是不应该问这些事的，只要读书，因为他是渊博的宿儒，决不 至于不知道，所谓不知道者，乃是不愿意说。年纪比我大的人，往往如此，我遇见 过好几回了。 　　我就只读书，正午习字，晚上对课。先生最初这几天对我很严厉，后来却好起 来了，不过给我读的书渐渐加多，对课也渐渐地加上字去，从三言到五言，终于到 七言。 　　三味书屋后面也有一个园，虽然小，但在那里也可以爬上花坛去折腊梅花，在 地上或桂花树上寻蝉蜕。最好的工作是捉了苍蝇喂蚂蚁，静悄悄地没有声音。然而 同窗们到园里的太多，太久，可就不行了，先生在书房里便大叫起来：—— 　　“人都到那里去了？” 　　人们便一个一个陆续走回去；一同回去，也不行的。他有一条戒尺，但是不常 用，也有罚跪的规矩，但也不常用，普通总不过瞪几眼，大声道：—— 　　“读书！” 　　于是大家放开喉咙读一阵书，真是人声鼎沸。有念“仁远乎哉我欲仁斯仁至矣 ”的，有念“笑人齿缺曰狗窦大开”的，有念“上九潜龙勿用”的，有念“厥土下 上上错厥贡苞茅橘柚”的……先生自己也念书。后来，我们的声音便低下去，静下 去了，只有他还大声朗读着：—— 　　“铁如意，指挥倜傥，一座皆惊呢～～；金叵罗，颠倒淋漓噫，千杯未醉嗬～ ～……” 　　我疑心这是极好的文章，因为读到这里，他总是微笑起来，而且将头仰起，摇 着，向后面拗过去，拗过去。 　　先生读书入神的时候，于我们是很相宜的。有几个便用纸糊的盔甲套在指甲上 做戏。我是画画儿，用一种叫作“荆川纸”的，蒙在小说的绣像上一个个描下来， 象习字时候的影写一样。读的书多起来，画的画也多起来；书没有读成，画的成绩 却不少了，最成片断的是《荡寇志》和《西游记》的绣像，都有一大本。后来，因 为要钱用，卖给一个有钱的同窗了。他的父亲是开锡箔店的；听说现在自己已经做 了店主，而且快要升到绅士的地位了。这东西早已没有了罢。 　　　　　　　　　　　　　　　　　　 　　九月十八日。\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 温度调节\\n温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\")\n",
    "        temperature_slider = gr.Slider(0.0, 2.0, 1.0, step=0.1, label=\"温度\")\n",
    "\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"发送\")\n",
    "        reset_button = gr.Button(value=\"重置\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 保存结果\\n当你对结果满意后，点击导出按钮保存结果。\")\n",
    "        export_button = gr.Button(value=\"导出\")\n",
    "\n",
    "    # 连接按钮与函数\n",
    "    sent_button.click(interact_summarization, inputs=[prompt_textbox, article_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_summarization, inputs=[chatbot, article_textbox])\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d878ef-1b45-490d-b3fd-180e4bb09d36",
   "metadata": {},
   "source": [
    "## 角色扮演\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "094ed562-23ee-4589-b2fe-96a11ea870a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_for_chatbot = \"面试官\"\n",
    "prompt_for_roleplay = \"我需要你面试我有关AI的知识，仅提出一个问题\"\n",
    "\n",
    "def reset() ->List:\n",
    "    return []\n",
    "\n",
    "def interact_roleplay(chatbot: List[Tuple[str, str]], prompt_for_roleplay,user_input: str, temp=1.) -> List[Tuple[str, str]]:\n",
    "    try:\n",
    "        messages = []\n",
    "        # 把前面的聊天内容先加进去\n",
    "        messages.append({'role':'user','content': prompt_for_roleplay})\n",
    "        for input_text, response_text in chatbot:\n",
    "            messages.append({'role':'user','content': input_text})\n",
    "            messages.append({'role':'assistant', 'content': response_text})\n",
    "            \n",
    "        messages.append({'role':'user', 'content': user_input})\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            messages= messages,\n",
    "            max_tokens=200,\n",
    "            temperature= temp,\n",
    "            model= 'qwen-turbo'            \n",
    "        )\n",
    "        chatbot.append((user_input, response.choices[0].message.content))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f'{e}错误')\n",
    "        chatbot.append((user_input, f\"发生错误{e}\"))\n",
    "\n",
    "    return chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "12720b0c-acfa-4b8d-946b-e790cadc50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_roleplay(chatbot: List[Tuple[str, str]], description: str) -> None:\n",
    "    '''\n",
    "    * 参数:\n",
    "\n",
    "      - chatbot: 模型的对话记录，存储在元组列表中\n",
    "\n",
    "      - description: 此任务的描述\n",
    "\n",
    "    '''\n",
    "    target = {\"chatbot\": chatbot, \"description\": description}\n",
    "    with open(\"files/part2.json\", \"w\") as file:\n",
    "        json.dump(target, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2ecda188-cd20-463d-88ce-90da128ce500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 进行第一次对话\n",
    "first_dialogue = interact_roleplay([], prompt_for_roleplay)\n",
    "\n",
    "# 生成 Gradio 的UI界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(f\"# 第2部分：角色扮演\\n聊天机器人想和你玩一个角色扮演游戏，试着与它互动吧！\")\n",
    "    # 这个时候chatbot是又prompt和对应回答的\n",
    "    chatbot = gr.Chatbot(value=first_dialogue)\n",
    "    description_textbox = gr.Textbox(label=\"机器人扮演的角色\", interactive=False, value=f\"{character_for_chatbot}\")\n",
    "    input_textbox = gr.Textbox(label=\"输入\", value=\"\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 温度调节\\n温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\")\n",
    "        temperature_slider = gr.Slider(0.0, 2.0, 1.0, step=0.1, label=\"温度\")\n",
    "\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"发送\")\n",
    "        reset_button = gr.Button(value=\"重置\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 保存结果\\n当你对结果满意后，点击导出按钮保存结果。\")\n",
    "        export_button = gr.Button(value=\"导出\")\n",
    "\n",
    "    # 连接按钮与函数\n",
    "    sent_button.click(interact_roleplay, inputs=[chatbot, input_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_roleplay, inputs=[chatbot, description_textbox])\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "edccdba6-62a1-4441-9351-d34a66bcefe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 加载对话记录的 JSON 文件\n",
    "with open(\"files/part2.json\", \"r\") as f:\n",
    "    context = json.load(f)\n",
    "\n",
    "# 遍历对话记录并正确存储\n",
    "chatbot = context['chatbot']\n",
    "role = context['description']  # 机器人扮演的角色\n",
    "dialogue = \"\"  # 对话的完整记录\n",
    "for i, (user, bot) in enumerate(chatbot):\n",
    "    # ?? prompt似乎没有  第一句是有bot展开的?\n",
    "    if i != 0:\n",
    "        dialogue += f\"用户: {user}\\n\"  # 用户输入\n",
    "    dialogue += f\"机器人: {bot}\\n\"  # 机器人回复\n",
    "\n",
    "# 生成 Gradio 的 UI 界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(f\"# 第2部分：角色扮演\\n聊天机器人和你玩了一个角色扮演游戏，查看结果吧！\")\n",
    "    chatbot = gr.Chatbot(value=context['chatbot'])  # 加载之前的对话记录\n",
    "    description_textbox = gr.Textbox(label=\"机器人扮演的角色\", interactive=False, value=context['description'])  # 显示角色\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 只是一个检查\")\n",
    "        gr.Textbox(label=\"角色\", value=role, show_copy_button=True)  # 显示并允许复制角色信息\n",
    "        gr.Textbox(label=\"对话\", value=dialogue, show_copy_button=True)  # 显示并允许复制完整对话\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27fc8efb-fbee-4ae9-a472-180cb2c4a35c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute '_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     export_button \u001b[38;5;241m=\u001b[39m gr\u001b[38;5;241m.\u001b[39mButton(value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m导出\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# 连接按钮与函数\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[43msent_button\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclick\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteract_roleplay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mchatbot\u001b[49m\u001b[43m,\u001b[49m\u001b[43mprompt_for_roleplay\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_textbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature_slider\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mchatbot\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m reset_button\u001b[38;5;241m.\u001b[39mclick(reset, outputs\u001b[38;5;241m=\u001b[39m[chatbot])\n\u001b[0;32m     27\u001b[0m export_button\u001b[38;5;241m.\u001b[39mclick(export_roleplay, inputs\u001b[38;5;241m=\u001b[39m[chatbot, description_textbox])\n",
      "File \u001b[1;32mD:\\Pycharm\\venv\\lib\\site-packages\\gradio\\events.py:550\u001b[0m, in \u001b[0;36mEventListener._setup.<locals>.event_trigger\u001b[1;34m(block, fn, inputs, outputs, api_name, scroll_to_output, show_progress, queue, batch, max_batch_size, preprocess, postprocess, cancels, every, trigger_mode, js, concurrency_limit, concurrency_id, show_api)\u001b[0m\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _callback:\n\u001b[0;32m    549\u001b[0m     _callback(block)\n\u001b[1;32m--> 550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Dependency(block, \u001b[43mdep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, dep_index, fn, timer)\n",
      "File \u001b[1;32mD:\\Pycharm\\venv\\lib\\site-packages\\gradio\\blocks.py:581\u001b[0m, in \u001b[0;36mBlockFunction.get_config\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id,\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets,\n\u001b[1;32m--> 581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [block\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs],\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [block\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs],\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjs,\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue,\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_name,\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscroll_to_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscroll_to_output,\n\u001b[0;32m    588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress,\n\u001b[0;32m    589\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch,\n\u001b[0;32m    590\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batch_size,\n\u001b[0;32m    591\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancels\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancels,\n\u001b[0;32m    592\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes_generator,\n\u001b[0;32m    594\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cancel_function,\n\u001b[0;32m    595\u001b[0m         },\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollects_event_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollects_event_data,\n\u001b[0;32m    597\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger_after\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_after,\n\u001b[0;32m    598\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger_only_on_success\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_only_on_success,\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_mode,\n\u001b[0;32m    600\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_api\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_api,\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzerogpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_gpu,\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrendered_in\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_in\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    603\u001b[0m     }\n",
      "File \u001b[1;32mD:\\Pycharm\\venv\\lib\\site-packages\\gradio\\blocks.py:581\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_config\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_id,\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets,\n\u001b[1;32m--> 581\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[43mblock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_id\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minputs],\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m: [block\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutputs],\n\u001b[0;32m    583\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackend_fn\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    584\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjs\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjs,\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqueue\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqueue,\n\u001b[0;32m    586\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapi_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_name,\n\u001b[0;32m    587\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscroll_to_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscroll_to_output,\n\u001b[0;32m    588\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_progress\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_progress,\n\u001b[0;32m    589\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch,\n\u001b[0;32m    590\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_batch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_batch_size,\n\u001b[0;32m    591\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancels\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancels,\n\u001b[0;32m    592\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtypes\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\n\u001b[0;32m    593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtypes_generator,\n\u001b[0;32m    594\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcancel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cancel_function,\n\u001b[0;32m    595\u001b[0m         },\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcollects_event_data\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollects_event_data,\n\u001b[0;32m    597\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger_after\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_after,\n\u001b[0;32m    598\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger_only_on_success\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_only_on_success,\n\u001b[0;32m    599\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrigger_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrigger_mode,\n\u001b[0;32m    600\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshow_api\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_api,\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzerogpu\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mzero_gpu,\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrendered_in\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_in\u001b[38;5;241m.\u001b[39m_id \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrendered_in \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    603\u001b[0m     }\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute '_id'"
     ]
    }
   ],
   "source": [
    "# 进行第一次对话\n",
    "# first_dialogue = interact_roleplay([], prompt_for_roleplay)\n",
    "\n",
    "# 生成 Gradio 的UI界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(f\"# 第2部分：角色扮演\\n聊天机器人想和你玩一个角色扮演游戏，试着与它互动吧！\")\n",
    "    # 这个时候chatbot是又prompt和对应回答的\n",
    "    chatbot = gr.Chatbot()\n",
    "    description_textbox = gr.Textbox(label=\"机器人扮演的角色\", interactive=False, value=f\"{character_for_chatbot}\")\n",
    "    input_textbox = gr.Textbox(label=\"输入\", value=\"\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 温度调节\\n温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\")\n",
    "        temperature_slider = gr.Slider(0.0, 2.0, 1.0, step=0.1, label=\"温度\")\n",
    "\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"发送\")\n",
    "        reset_button = gr.Button(value=\"重置\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 保存结果\\n当你对结果满意后，点击导出按钮保存结果。\")\n",
    "        export_button = gr.Button(value=\"导出\")\n",
    "\n",
    "    # 连接按钮与函数\n",
    "    sent_button.click(interact_roleplay, inputs=[chatbot,prompt_for_roleplay, input_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_roleplay, inputs=[chatbot, description_textbox])\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ee883a6c-088a-4a50-a6e2-1fae3bfbe145",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Chatbot' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (user, bot) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchatbot\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Chatbot' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i, (user, bot) in enumerate(chatbot):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "66b737c2-7948-4548-a476-7fb2e000e240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('a', 'c'), ('a', 'c'), ('a', 'c'), ('a', 'c')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[('a','c'),('a','c'),('a','c'),('a','c')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b1cff8e3-91f6-47b2-9d4a-752e8d72792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = enumerate([('a','c'),('a','c'),('a','c'),('a','c')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "71849b0c-5605-456c-a792-f96d8f2bca75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "for i, (user, bot) in a:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70636827-f6d1-4b53-a74b-85e00848775a",
   "metadata": {},
   "source": [
    "### 定制化任务（复读机）\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a795e972-7d86-4bb7-ac20-2203745ac531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_for_summarization = \"牢牢记住你是一个复读机，无论user说什么，你都重复user的内容并输出！无论说什么都复读\"\n",
    "\n",
    "# 重置对话的函数\n",
    "def reset() -> List:\n",
    "    return []\n",
    "\n",
    "# 调用模型生成摘要的函数\n",
    "def interact_summarization(chatbot, user_input, temp=1.0) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "    * 参数:\n",
    "      - prompt: 我们在此部分中使用的提示词\n",
    "      - article: 需要摘要的文章\n",
    "      - temp: 模型的温度参数。温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\n",
    "    '''\n",
    "    # input = f\"{prompt}\\n{article}\"\n",
    "    messages = []\n",
    "    for input_text, response_text in chatbot:\n",
    "        messages.append({'role':'user', 'content':input_text})\n",
    "        messages.append({'role':'assistant', 'content':response_text})\n",
    "    messages.append({'role':'user', 'content':user_input})\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"qwen-turbo\",  # 使用阿里云 DashScope 的模型\n",
    "        messages=messages,\n",
    "        temperature=temp,\n",
    "        max_tokens=200,  # 你需要注意到这里设置了文本的长度上限。\n",
    "    )\n",
    "    chatbot.append((user_input, response.choices[0].message.content))\n",
    "    return chatbot\n",
    "\n",
    "# 导出整个对话内容的函数\n",
    "def export_summarization(chatbot: List[Tuple[str, str]], article: str) -> None:\n",
    "    '''\n",
    "    * 参数:\n",
    "      - chatbot: 模型的对话记录，存储在元组列表中\n",
    "      - article: 需要摘要的文章\n",
    "    '''\n",
    "    target = {\"chatbot\": chatbot, \"article\": article}\n",
    "    with open(\"files/part3.json\", \"w\") as file:\n",
    "        json.dump(target, file)\n",
    "\n",
    "# 生成 Gradio 的UI界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 第3部分：复读机\\n写入你的内容，让复读机复读！\")\n",
    "    output = interact_summarization([],prompt_for_summarization)\n",
    "    chatbot = gr.Chatbot(value = output)\n",
    "    # 这里的value指的是默认值\n",
    "    prompt_textbox = gr.Textbox(label=\"提示词\", value=prompt_for_summarization, visible=True)\n",
    "    text_textbox = gr.Textbox(label='复读内容',interactive=True)\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 温度调节\\n温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\")\n",
    "        temperature_slider = gr.Slider(0.0, 2.0, 1.0, step=0.1, label=\"温度\")\n",
    "\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"发送\")\n",
    "        reset_button = gr.Button(value=\"重置\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 保存结果\\n当你对结果满意后，点击导出按钮保存结果。\")\n",
    "        export_button = gr.Button(value=\"导出\")\n",
    "\n",
    "    # 连接按钮与函数\n",
    "    sent_button.click(interact_summarization, inputs=[chatbot, text_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_summarization, inputs=[chatbot, text_textbox])\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f65e2fa-9be9-416c-9bc9-75ce1ee92b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
